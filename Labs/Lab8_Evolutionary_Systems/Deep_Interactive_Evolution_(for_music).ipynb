{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Interactive_Evolution_(for_music).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as9jtKN899Cm",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "To demonstrate the generality of the algorithm to any latent variable model, we use a pretrained VAE model by Google Magenta, MusicVAE (found here: https://colab.research.google.com/notebook#fileId=/v2/external/notebooks/magenta/music_vae/music_vae.ipynb).\n",
        "\n",
        "Installs and imports all packages for the Magenta MusicVAE, alongside loading the basic 2-bar loop model (a bidirectional LSTM encoder based VAE). This notebook is meant to run natively on google cloud in Colaboratory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54-G9Pg4udN7",
        "colab_type": "text"
      },
      "source": [
        "# Deep Interactive Evolution (for music)\n",
        "\n",
        "This is an unofficial implementation of the algorithm found in the paper \"Deep Interactive Evolution\" (https://arxiv.org/abs/1801.08230). In contrast to the original paper, this implementation uses a VAE (instead of a GAN) trained on 2-bar music (instead of images), to evolve a 2-bar sample the user prefers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6LJkEOC1yJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "print 'Copying checkpoints and example MIDI from GCS. This may take a few minutes...'\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab2/* /content/\n",
        "\n",
        "print 'Installing dependencies...'\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "if glob.glob('/content/magenta*.whl'):\n",
        "  !pip install -qU /content/magenta*.whl\n",
        "else:\n",
        "  !pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
        "import ctypes.util\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return ctypes.util.find_library(lib)\n",
        "\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "\n",
        "print 'Importing libraries and defining some helper functions...'\n",
        "from google.colab import files\n",
        "import magenta.music as mm\n",
        "from magenta.music.sequences_lib import concatenate_sequences\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def play(note_sequence):\n",
        "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
        "  \n",
        "def slerp(p0, p1, t):\n",
        "  \"\"\"Spherical linear interpolation.\"\"\"\n",
        "  omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)), np.squeeze(p1/np.linalg.norm(p1))))\n",
        "  so = np.sin(omega)\n",
        "  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
        "\n",
        "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
        "                assert_same_length=True, temperature=0.5, \n",
        "                individual_duration=4.0):\n",
        "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
        "  _, mu, _ = model.encode([start_seq, end_seq], assert_same_length)\n",
        "  z = np.array([slerp(mu[0], mu[1], t) for t in np.linspace(0, 1, num_steps)])\n",
        "  note_sequences = model.decode(\n",
        "      length=max_length,\n",
        "      z=z,\n",
        "      temperature=temperature)\n",
        "\n",
        "  print 'Start Seq Reconstruction'\n",
        "  play(note_sequences[0])\n",
        "  print 'End Seq Reconstruction'\n",
        "  play(note_sequences[-1])\n",
        "  print 'Mean Sequence'\n",
        "  play(note_sequences[num_steps // 2])\n",
        "  print 'Start -> End Interpolation'\n",
        "  interp_seq = concatenate_sequences(note_sequences, [individual_duration] * len(note_sequences))\n",
        "  play(interp_seq)\n",
        "  mm.plot_sequence(interp_seq)\n",
        "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "\n",
        "print 'Done'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDuUxK64aVFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the pre-trained model.\n",
        "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
        "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/mel_2bar_big.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHV0887fh6Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rangek = 10\n",
        "z_length = 512\n",
        "p = 0.5\n",
        "foreign = 2\n",
        "model = mel_2bar\n",
        "np.random.seed(0)\n",
        "\n",
        "z = np.random.randn(rangek, z_length)\n",
        "m, n = rangek, z_length\n",
        "\n",
        "print 'Evolution hyperparamter initialization and model definiton complete'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkwmYjyY-0yC",
        "colab_type": "text"
      },
      "source": [
        "Some helper functions for the evolution process, as outlined in algorithm 2 of the paper\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05egthvZ-xyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def uniform(population):\n",
        "    pop_len = \n",
        "    a = population[np.random.randint(0, pop_len)]\n",
        "    b = \n",
        "    mask =\n",
        "    return \n",
        "\n",
        "def mutate(individual, std):\n",
        "    mutate_cond = \n",
        "    noise = \n",
        "    return \n",
        "\n",
        "def evolve(z, indices, mutate_rate, shuffle=True):\n",
        "    selections = \n",
        "    mutate_var = \n",
        "\n",
        "    diff = \n",
        "    x = \n",
        "    cross = \n",
        "\n",
        "    x = \n",
        "    new = \n",
        "\n",
        "    selections = \n",
        "\n",
        "    z = \n",
        "    \n",
        "    # if not shuffle, the first n(selected) samples are mutated selected samples, \n",
        "    # the last n(foreign) samples are foreign samples, and all samples inbetween are crossovers\n",
        "    if shuffle:\n",
        "        np.random.shuffle(z) \n",
        "    return z\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4K6ywuAr7MD",
        "colab_type": "text"
      },
      "source": [
        "# Deep Interactive Evolution\n",
        "To simulate the evolution process keep running the following three cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tapRu9u0lKvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "note_sequences = \n",
        "\n",
        "print 'Start Seq Reconstruction'\n",
        "for i in range(rangek):\n",
        "  print i \n",
        "  play(note_sequences[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjl-DGzBtBXk",
        "colab_type": "text"
      },
      "source": [
        "If at any stage you'd like to seperately store a sample in memory, run the next cell with the index of the desired sample. Else, do not run, skip. This does not influence the actual evolution process, it just assigns the latent code of a sample you liked most so far to the best_yet variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwtf37qcAcnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_yet = z[0] #insert the index of the best so far\n",
        "play(model.decode(\n",
        "      length=32,\n",
        "      z=best_yet.reshape(-1, 512),\n",
        "      temperature=0.8)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ikTMNH1si5c",
        "colab_type": "text"
      },
      "source": [
        "Replace the elements in list selected with the actual indices of the samples you wish to keep and run the next cell, after which, restart the \"loop\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RA_TfBh5g3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_selected = \n",
        "z = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwN1T5BxdVmB",
        "colab_type": "text"
      },
      "source": [
        "Now, rerun the cell that generated all the samples. With the z's evolved, it will now generate samples from the new batch of z latent vectors"
      ]
    }
  ]
}
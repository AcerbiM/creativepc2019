{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "colab": {
      "name": "Sketch_RNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD10qsS5M32C",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjvOdYOjMZ_b",
        "colab_type": "code",
        "outputId": "99e9345a-d25d-4784-a007-2147ace097f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "# import the required libraries\n",
        "import numpy as np\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "import time\n",
        "import random\n",
        "import  cPickle\n",
        "import codecs\n",
        "import collections\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from six.moves import xrange"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGKq37TOM6f9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d0c40dc-c432-411d-8d73-7c17bfcef3ab"
      },
      "source": [
        "# libraries required for visualisation:\n",
        "from IPython.display import SVG, display\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set numpy output to something sensible\n",
        "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)\n",
        "\n",
        "!pip install -qU svgwrite\n",
        "import svgwrite # conda install -c omnia svgwrite=1.1.6\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▉                           | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_q3OxSWNBiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.info(\"TensorFlow Version: %s\", tf.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMLgywarNDuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d506dff-e97a-40ab-e911-65306b37e497"
      },
      "source": [
        "!pip install -q magenta\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 491kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 512kB 2.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM_NVKTNNHyy",
        "colab_type": "code",
        "outputId": "f473e392-b9f5-49b2-c92b-98d9fa435058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# import our command line tools\n",
        "from magenta.models.sketch_rnn.sketch_rnn_train import *\n",
        "from magenta.models.sketch_rnn.model import *\n",
        "from magenta.models.sketch_rnn.utils import *\n",
        "from magenta.models.sketch_rnn.rnn import *"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1205 11:25:19.695929 140259815909248 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/note_sequence_io.py:60: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1205 11:25:19.715667 140259815909248 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1205 11:25:21.609268 140259815909248 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/sketch_rnn/sketch_rnn_train.py:35: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1205 11:25:21.610960 140259815909248 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/sketch_rnn/sketch_rnn_train.py:35: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MAXD1SVNOBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# little function that displays vector images and saves them to .svg\n",
        "def draw_strokes(data, factor=0.05, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
        "  tf.gfile.MakeDirs(os.path.dirname(svg_filename))\n",
        "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
        "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
        "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
        "  lift_pen = 1\n",
        "  abs_x = 25 - min_x \n",
        "  abs_y = 25 - min_y\n",
        "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
        "  command = \"m\"\n",
        "  for i in xrange(len(data)):\n",
        "    if (lift_pen == 1):\n",
        "      command = \"m\"\n",
        "    elif (command != \"l\"):\n",
        "      command = \"l\"\n",
        "    else:\n",
        "      command = \"\"\n",
        "    x = float(data[i,0])/factor\n",
        "    y = float(data[i,1])/factor\n",
        "    lift_pen = data[i, 2]\n",
        "    p += command+str(x)+\",\"+str(y)+\" \"\n",
        "  the_color = \"black\"\n",
        "  stroke_width = 1\n",
        "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
        "  dwg.save()\n",
        "  display(SVG(dwg.tostring()))\n",
        "\n",
        "# generate a 2D grid of many vector drawings\n",
        "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
        "  def get_start_and_end(x):\n",
        "    x = np.array(x)\n",
        "    x = x[:, 0:2]\n",
        "    x_start = x[0]\n",
        "    x_end = x.sum(axis=0)\n",
        "    x = x.cumsum(axis=0)\n",
        "    x_max = x.max(axis=0)\n",
        "    x_min = x.min(axis=0)\n",
        "    center_loc = (x_max+x_min)*0.5\n",
        "    return x_start-center_loc, x_end\n",
        "  x_pos = 0.0\n",
        "  y_pos = 0.0\n",
        "  result = [[x_pos, y_pos, 1]]\n",
        "  for sample in s_list:\n",
        "    s = sample[0]\n",
        "    grid_loc = sample[1]\n",
        "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
        "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
        "    start_loc, delta_pos = get_start_and_end(s)\n",
        "\n",
        "    loc_x = start_loc[0]\n",
        "    loc_y = start_loc[1]\n",
        "    new_x_pos = grid_x+loc_x\n",
        "    new_y_pos = grid_y+loc_y\n",
        "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
        "\n",
        "    result += s.tolist()\n",
        "    result[-1][2] = 1\n",
        "    x_pos = new_x_pos+delta_pos[0]\n",
        "    y_pos = new_y_pos+delta_pos[1]\n",
        "  return np.array(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuH9ZtjUNTaC",
        "colab_type": "text"
      },
      "source": [
        "Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H4yWOXvNRsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/'\n",
        "models_root_dir = '/tmp/sketch_rnn/models'\n",
        "model_dir = '/tmp/sketch_rnn/models/aaron_sheep/layer_norm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq1_wAScNVzX",
        "colab_type": "code",
        "outputId": "7796c0df-5206-4bf2-bcf1-0e6a9d280b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "download_pretrained_models(models_root_dir=models_root_dir)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1205 11:25:30.623168 140259815909248 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/sketch_rnn/sketch_rnn_train.py:98: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "I1205 11:25:30.626854 140259815909248 sketch_rnn_train.py:105] Downloading pretrained models from http://download.magenta.tensorflow.org/models/sketch_rnn.zip...\n",
            "I1205 11:25:39.576687 140259815909248 sketch_rnn_train.py:107] Download complete.\n",
            "I1205 11:25:39.581824 140259815909248 sketch_rnn_train.py:108] Unzipping /tmp/sketch_rnn/models/sketch_rnn.zip...\n",
            "I1205 11:25:41.739905 140259815909248 sketch_rnn_train.py:111] Unzipping complete.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpzDJY-O3PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_env_compatible(data_dir, model_dir):\n",
        "  \"\"\"Loads environment for inference mode, used in jupyter notebook.\"\"\"\n",
        "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
        "  # to work with depreciated tf.HParams functionality\n",
        "  model_params = sketch_rnn_model.get_default_hparams()\n",
        "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
        "    data = json.load(f)\n",
        "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
        "  for fix in fix_list:\n",
        "    data[fix] = (data[fix] == 1)\n",
        "  model_params.parse_json(json.dumps(data))\n",
        "  return load_dataset(data_dir, model_params, inference_mode=True)\n",
        "\n",
        "def load_model_compatible(model_dir):\n",
        "  \"\"\"Loads model for inference mode, used in jupyter notebook.\"\"\"\n",
        "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
        "  # to work with depreciated tf.HParams functionality\n",
        "  model_params = sketch_rnn_model.get_default_hparams()\n",
        "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
        "    data = json.load(f)\n",
        "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
        "  for fix in fix_list:\n",
        "    data[fix] = (data[fix] == 1)\n",
        "  model_params.parse_json(json.dumps(data))\n",
        "\n",
        "  model_params.batch_size = 1  # only sample one at a time\n",
        "  eval_model_params = sketch_rnn_model.copy_hparams(model_params)\n",
        "  eval_model_params.use_input_dropout = 0\n",
        "  eval_model_params.use_recurrent_dropout = 0\n",
        "  eval_model_params.use_output_dropout = 0\n",
        "  eval_model_params.is_training = 0\n",
        "  sample_model_params = sketch_rnn_model.copy_hparams(eval_model_params)\n",
        "  sample_model_params.max_seq_len = 1  # sample one point at a time\n",
        "  return [model_params, eval_model_params, sample_model_params]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AnIPy4IO6Kn",
        "colab_type": "code",
        "outputId": "cb433018-bbfc-46a6-86d4-a94e83e5e689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "[train_set, valid_set, test_set, hps_model, eval_hps_model, sample_hps_model] = load_env_compatible(data_dir, model_dir)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1205 11:27:07.066061 140259815909248 sketch_rnn_train.py:133] Downloading http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/aaron_sheep.npz\n",
            "I1205 11:27:09.948067 140259815909248 sketch_rnn_train.py:143] Loaded 7400/300/300 from aaron_sheep.npz\n",
            "I1205 11:27:10.329495 140259815909248 sketch_rnn_train.py:160] Dataset combined: 8000 (7400/300/300), avg len 125\n",
            "I1205 11:27:10.336760 140259815909248 sketch_rnn_train.py:167] model_params.max_seq_len 250.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total images <= max_seq_len is 7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I1205 11:27:11.235851 140259815909248 sketch_rnn_train.py:210] normalizing_scale_factor 18.5198.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total images <= max_seq_len is 300\n",
            "total images <= max_seq_len is 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTdHVQSbPy2G",
        "colab_type": "code",
        "outputId": "aec417b9-5c3e-459b-d45a-1757461aa9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# construct the sketch-rnn model here:\n",
        "reset_graph()\n",
        "model = Model(hps_model)\n",
        "eval_model = Model(eval_hps_model, reuse=True)\n",
        "sample_model = Model(sample_hps_model, reuse=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1205 11:28:00.480937 140259815909248 model.py:87] Model using gpu.\n",
            "I1205 11:28:00.490211 140259815909248 model.py:175] Input dropout mode = False.\n",
            "I1205 11:28:00.493602 140259815909248 model.py:176] Output dropout mode = False.\n",
            "I1205 11:28:00.495465 140259815909248 model.py:177] Recurrent dropout mode = True.\n",
            "I1205 11:28:04.084726 140259815909248 model.py:87] Model using gpu.\n",
            "I1205 11:28:04.087048 140259815909248 model.py:175] Input dropout mode = 0.\n",
            "I1205 11:28:04.088798 140259815909248 model.py:176] Output dropout mode = 0.\n",
            "I1205 11:28:04.090012 140259815909248 model.py:177] Recurrent dropout mode = 0.\n",
            "I1205 11:28:04.501352 140259815909248 model.py:87] Model using gpu.\n",
            "I1205 11:28:04.503032 140259815909248 model.py:175] Input dropout mode = 0.\n",
            "I1205 11:28:04.508733 140259815909248 model.py:176] Output dropout mode = 0.\n",
            "I1205 11:28:04.510029 140259815909248 model.py:177] Recurrent dropout mode = 0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G2uMr9NP4-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLEH7iLiP7Ir",
        "colab_type": "code",
        "outputId": "a0c5ac64-9444-4c5b-bb04-8cc0c14ebd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# loads the weights from checkpoint into our model\n",
        "load_checkpoint(sess, model_dir)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1205 11:28:08.316930 140259815909248 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/sketch_rnn/sketch_rnn_train.py:240: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1205 11:28:08.318443 140259815909248 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/sketch_rnn/sketch_rnn_train.py:240: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "I1205 11:28:08.407704 140259815909248 sketch_rnn_train.py:242] Loading model /tmp/sketch_rnn/models/aaron_sheep/layer_norm/vector.\n",
            "I1205 11:28:08.412688 140259815909248 saver.py:1284] Restoring parameters from /tmp/sketch_rnn/models/aaron_sheep/layer_norm/vector\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tVZOfkyP9iE",
        "colab_type": "text"
      },
      "source": [
        "We define two convenience functions to encode a stroke into a latent vector, and decode from latent vector to stroke.\n",
        "\n",
        "Strokes object variable is the list of data points, which are sequences of strokes, represented as a 2D NumPy array of xy-offsets and the pen state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a7qBUHqP_Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(input_strokes):\n",
        "  strokes = to_big_strokes(input_strokes).tolist() # Converts from stroke-3 to stroke-5 format and pads to given length.\n",
        "  strokes.insert(0, [0, 0, 1, 0, 0]) # insert special start token\n",
        "  seq_len = [len(input_strokes)] \n",
        "  draw_strokes(to_normal_strokes(np.array(strokes))) # Convert from stroke-5 format (from sketch-rnn paper) back to stroke-3.\n",
        "  return sess.run(eval_model.batch_z, feed_dict={eval_model.input_data: [strokes], eval_model.sequence_lengths: seq_len})[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LukPhHL_QEIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(z_input=None, draw_mode=True, temperature=0.1, factor=0.05):\n",
        "  z = None\n",
        "  if z_input is not None:\n",
        "    z = [z_input]\n",
        "  sample_strokes, m = sample(sess, sample_model, seq_len=eval_model.hps.max_seq_len, temperature=temperature, z=z)\n",
        "  strokes = to_normal_strokes(sample_strokes)\n",
        "  if draw_mode:\n",
        "    draw_strokes(strokes, factor)\n",
        "  return strokes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW_D6cWPQHYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a sample drawing from the test set, and render it to .svg\n",
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYN-qEpyQsdJ",
        "colab_type": "text"
      },
      "source": [
        "Let's try to encode the sample stroke into latent vector $z$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrDxcJZNQuJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcegCcV-QxHI",
        "colab_type": "text"
      },
      "source": [
        "convert z back to drawing at temperature of 0.8\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8NnRA9HQzKb",
        "colab_type": "code",
        "outputId": "87370467-b4e4-471d-fd0e-e4ebeecbaa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# ..."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"186.939552427\" version=\"1.1\" width=\"277.518275776\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"186.939552427\" width=\"277.518275776\" x=\"0\" y=\"0\"/><path d=\"M37.0344223551,40.7928007301 m-2.36397191882,-2.12554186583 l-6.21909737587,0.00114537731861 -0.00215974752791,6.71367704868 l-3.44693869352,-9.89640511762e-06 -0.00225461932132,-1.91736325622 l6.01836919785,7.5421667099 14.0526497364,-1.53689920902 l-0.000419665993832,1.24262213707 1.68687984347,-1.37435615063 l4.31334167719,6.59418702126 8.44624936581,-9.17069883144e-05 l-0.000574980040255,-3.86471092701 2.2635050118,-2.16770559549 l-0.645576044917,-0.00074036535807 -3.69162917137,-3.69954705238 l0.000350545051333,-3.95911663771 -3.08905094862,-2.23937273026 m-6.41855537891,7.03520774841 l-1.15104861557,-3.14627289772 -1.59765169024,0.035703771282 l-0.000316516052408,1.66880577803 0.190077759326,-1.3518306613 l-4.68039095402,-0.897263884544 m7.17419862747,2.17587828636 l0.925638154149,-3.6012250185 4.39326405525,-9.67498181126e-05 l-3.7274903059,-8.42247288801e-06 2.66449421644,0.000466525343654 l-3.05719435215,-1.30523115396 -2.01772481203,1.22216366231 l1.06054544449,-0.869468301535 2.88676679134,0.00164449505974 m7.01881170273,2.18524083495 l26.8847513199,-3.08985888958 11.0019338131,0.488976053894 l2.69577383995,2.84650593996 m-53.6805152893,-10.6287360191 l0.996321886778,-2.55972921848 7.72049665451,-5.21201550961 l9.44216609001,0.00160688272445 2.81347602606,4.90765333176 m-5.16233325005,13.1286728382 l2.28748455644,0.00128857631353 7.02129304409,-4.37784582376 l38.2449650764,-0.421321727335 m-42.2374296188,21.1751008034 l-0.966361686587,6.57325744629 1.63051515818,2.78723865747 l4.50367599726,1.1798722297 18.7670004368,4.91456717253 l3.61192286015,13.0539512634 -4.3860989809,21.3126540184 l9.5799601078,5.87026953697 7.86699354649,-0.000829460259411 l7.34116375446,2.05542862415 7.15013861656,-4.31239247322 l16.4294278622,8.03493618965 3.73229652643,8.31368982792 l23.3000421524,1.00170604885 12.1709215641,-3.3488664031 l38.3446407318,-0.274968538433 5.95131695271,-3.15690994263 l9.90955412388,-1.96760699153 6.26230418682,-4.3127605319 l4.04696583748,-7.2877073288 8.75756800175,-6.97968780994 l2.46842518449,-6.1585855484 -1.28855109215,-6.23873472214 l-0.00154098015628,-11.7091870308 -5.41252493858,-4.90083932877 l-3.48484188318,0.000238122847804 2.31116101146,-15.445305109 l-2.9193970561,-4.55266952515 -3.40068131685,-0.742961540818 l-2.48955965042,1.86084657907 -6.09036147594,-0.602668635547 l0.000531385849172,-4.54393684864 -7.71552681923,-13.5441195965 l-10.7991349697,3.17184388638 -23.1368374825,5.52805900574 l-9.92042541504,-8.56536448002 -9.73658502102,-1.38183578849 l-15.1684045792,0.00255003076745 -14.2559993267,5.73903560638 l-2.3502895236,2.62063860893 1.57219678164,0.00120099233754 l-5.11377871037,3.48810046911 -8.21868598461,4.99582499266 l-5.20337998867,0.00117905939987 -3.19945722818,6.86188459396 l0.00045426269935,4.66349691153 0.00130799759063,5.60737848282 l-4.90742623806,4.17227238417 -4.0543961525,-1.97380373379e-06 l3.92670563087e-05,1.61702752113 -7.48182356358,4.40477818251 l-2.38030210137,2.66083270311 -5.00878512859,6.14390864939e-05 l-4.45387810469,4.443564713 m33.1864356995,21.2932157516 l0.00406282808399,17.8521680832 -0.000832616497064,11.6716372967 l-4.19507861137,8.71700108051 -6.59625768661,7.07271874489e-05 l-9.19852972031,4.72614586353 -3.48988175392,4.96862977743 l5.31277656555,5.66284537315 6.06076359749,0.722237899899 l3.28278452158,-2.42570742965 2.89642244577,-6.74063503742 l9.87172484398,-31.6375827789 0.00250401615631,4.81560319662 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crFAUO5NQ9Td",
        "colab_type": "text"
      },
      "source": [
        "Create generated grid at various temperatures from 0.1 to 1.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQJCkNqIQ-2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stroke_list = []\n",
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74H_IWFIRGrc",
        "colab_type": "text"
      },
      "source": [
        "# Latent space Interpolation between $z_0$ and $z_1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRnVuSwkRMld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a sample drawing from the test set, and render it to .svg\n",
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxTpUeRORQ0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S02-H7-RTee",
        "colab_type": "text"
      },
      "source": [
        "Now we interpolate between sheep $z_0$ and sheep $z_1$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qynMvVfPRVF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idboV6YnRX9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for every latent vector in z_list, sample a vector image\n",
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsvT0BOIRd9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekt1CBdSRkWm",
        "colab_type": "text"
      },
      "source": [
        "# Unconditional Generation\n",
        "\n",
        "We'll load the Flamingo model and try decoder-only generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Jv5q9vRr6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = '/tmp/sketch_rnn/models/flamingo/lstm_uncond'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJR-TQuMRuD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byGYcMarRvh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the sketch-rnn model here:\n",
        "reset_graph()\n",
        "model = Model(hps_model)\n",
        "eval_model = Model(eval_hps_model, reuse=True)\n",
        "sample_model = Model(sample_hps_model, reuse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAB9nT1Rx2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X33o2btURzgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loads the weights from checkpoint into our model\n",
        "load_checkpoint(sess, model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezntCdLzR4I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomly unconditionally generate 10 examples\n",
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2iPuPruR5wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtMHOVBCSEyD",
        "colab_type": "text"
      },
      "source": [
        "Let's load the owl model, and generate two sketches using two random IID gaussian latent vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBPrIv8vSGsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = '/tmp/sketch_rnn/models/owl/lstm'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj1D_xClSJM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
        "# construct the sketch-rnn model here:\n",
        "reset_graph()\n",
        "model = Model(hps_model)\n",
        "eval_model = Model(eval_hps_model, reuse=True)\n",
        "sample_model = Model(sample_hps_model, reuse=True)\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# loads the weights from checkpoint into our model\n",
        "load_checkpoint(sess, model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3iwhHm2SNfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_0 = #..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6n9j93PSOpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_1 = #...\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHoKEwiSYLY",
        "colab_type": "text"
      },
      "source": [
        "Let's interpolate between the two owls $z_0$ and $z_1$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ColaqjpSXUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#...."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lOAzl4_SdlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW8VSS5dSjCc",
        "colab_type": "text"
      },
      "source": [
        "Let's load the model trained on both cats and buses! catbus!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaOl4icISkqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = '/tmp/sketch_rnn/models/catbus/lstm'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irgrw9TDSmNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
        "# construct the sketch-rnn model here:\n",
        "reset_graph()\n",
        "model = Model(hps_model)\n",
        "eval_model = Model(eval_hps_model, reuse=True)\n",
        "sample_model = Model(sample_hps_model, reuse=True)\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# loads the weights from checkpoint into our model\n",
        "load_checkpoint(sess, model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNZlGDRKSqmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_1 = #...."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QrzuCKFStdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_0 = #..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3De4P4WmSz5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_list = [] # interpolate spherically between z_1 and z_0\n",
        "#....\n",
        "#....\n",
        "#....\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxlReoYvS2oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#....\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyEiR2-IS54g",
        "colab_type": "text"
      },
      "source": [
        "Why stop here? Let's load the model trained on both elephants and pigs!!!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XFnOGaHS79V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = '/tmp/sketch_rnn/models/elephantpig/lstm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCzyeIpSTARR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[hps_model, eval_hps_model, sample_hps_model] = load_model_compatible(model_dir)\n",
        "# construct the sketch-rnn model here:\n",
        "reset_graph()\n",
        "model = Model(hps_model)\n",
        "eval_model = Model(eval_hps_model, reuse=True)\n",
        "sample_model = Model(sample_hps_model, reuse=True)\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# loads the weights from checkpoint into our model\n",
        "load_checkpoint(sess, model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBUVt5McTC3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_0 = #....\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2z_xWiWTEga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_1 = #....\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Fc7bRXTGpN",
        "colab_type": "text"
      },
      "source": [
        "Tribute to an episode of South Park: The interpolation between an Elephant and a Pig\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYdd4gDeTHhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_list = [] # interpolate spherically between z_1 and z_0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqdIr9pgTJP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stroke_grid = make_grid_svg(reconstructions, grid_space_x=25.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYg1xbDWTKVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_strokes(stroke_grid, factor=0.05)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}